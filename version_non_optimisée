#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Sep  5 10:23:23 2019

@author: p
"""

from requests import get
from bs4 import BeautifulSoup
import pandas as pd
import datetime
import time


# Debut du decompte du temps
start_time = time.time()


#https://www.dataquest.io/blog/web-scraping-beautifulsoup/
poste = []
address = []
date_publication = []
offre_number= []
description = []
Qualification = []
secteur_activity = []       
entreprise = []
partenaire = []
lien_propre = []
description = []
address = []
urlgeneral=get('https://candidat.pole-emploi.fr/offres/recherche?motsCles=data&offresPartenaires=false&range=0-0&rayon=10&tri=0')
soup_general= BeautifulSoup(urlgeneral.text, 'html.parser')
soup_general= str(soup_general.find_all('h1')).replace('[<h1 class="title">',"")
index= soup_general.index(" offres")
n_index = int(soup_general[0:index])
print(int(soup_general[0:index]))

"ranges_offres = [str(i) for i in range(0,n_index)]    "
ranges_offres = [str(i) for i in range(0,n_index)]    
for ranges in ranges_offres:
    response = get('https://candidat.pole-emploi.fr/offres/recherche?motsCles=data&offresPartenaires=false&range='+ranges+'-'+ranges+'&rayon=10&tri=0')
    soup = BeautifulSoup(response.text, "html.parser")  
    print(soup)

 
    for result in soup.find_all(class_ ='result'):
        lien_propre.append(result.find('a', class_ ='btn-reset')['href'])
        print(lien_propre)



listebis = []
dico = {}
            
for i in lien_propre:
    url = 'https://candidat.pole-emploi.fr' + i
    response = get(url)
    soup = BeautifulSoup(response.text, "lxml")  
    poste = str(soup.find_all("h2")[1:2])
    poste = poste[31:len(poste)].replace("\n</h2>]","")        
    print(poste)
    print("################################################")
    address = str(soup.find_all("span", itemprop={"name"}))
    address = address[23:len(address)].split('<')[0]
    print(address)
    print("################################################")
    date_publication = str(soup.find_all("span", itemprop={"datePosted"}))
    date_publication = date_publication[51:len(date_publication)].replace("\n</span>]","") 
    print(date_publication)
    print("################################################")
    offre_number = str(soup.find_all("span", itemprop={"value"})[0:1])
    offre_number=offre_number[24:len(offre_number)].replace("</span>]","") 
    print(offre_number)
    print("################################################")     

    skills=''
    xp=''
    liste=[]
    """    on récupère les éléments qui nous interesse et on les nettoie    """           
    description = str(soup.find_all("div", itemprop={"description"}))
    description = description[70:len(description)].replace('</p></div>]',"")        
    print(description)
    print("################################################")     
    experience = str(soup.find_all('span', attrs={"class":"skill-name"})) 
    
    for x in experience.split('span'):
        """       on récupère les elements definit dans les elses dans des variables avant de les ajouter dans une liste        """
        if ("skills" in x):
 
            skills += x+"|"
            skills = skills.replace('class="skill-name" itemprop="skills">','').replace('</','')          
        
        elif ("experienceRequirements" in x):
            xp += x.replace('</','')
            xp = xp[54:len(xp)]  
    print(skills)
    print(xp)
    print("################################################")     
    Qualification = str(soup.find_all("span", itemprop={"qualifications"}))
    Qualification = Qualification[33:len(Qualification)].replace("</span>]","")
    print(Qualification)
    print("################################################")
    secteur_activity = str(soup.find_all("span", itemprop={"industry"}))
    secteur_activity = secteur_activity[27:len(secteur_activity)].replace('</span>]',"")
    print(secteur_activity)
    print("################################################")
###########################################A CHECK ############################################################
    entreprise = str(soup.find_all('h4', attrs={"class":"t4 title"})[0:1]) 
    entreprise = entreprise[22:len(entreprise)].replace("</h4>]","").replace("\n","")
    print(entreprise)
    print("################################################")
    partenaire = str(soup.find("a", {"id": "idLienPartenaire"}))
    try:
        idx=partenaire.index("href=")
        idP=partenaire.index("id=")
        partenaire = partenaire[idx:idP].replace('href="','').replace('"','')
    except:
        partenaire="Pas de lien"
    print(partenaire)
    print("################################################")
    """    ajout des elems dans une liste     """
    liste.append(poste)
    liste.append(address)
    liste.append(date_publication)
    liste.append(offre_number)#ref
    liste.append(description)
    liste.append(skills)
    liste.append(xp)
    liste.append(Qualification)
    liste.append(secteur_activity)           
    liste.append(entreprise)
    liste.append(partenaire)
    """    ajout de chaque liste dans une autre liste ( double liste pour faire )    """
    listebis.append(liste)
c=0
for i in listebis:
    """    transformation de la liste en dictionnaire    """
    date = str(datetime.datetime.now())  
    c += 1
    dico[date] = i
"""transformation du dictionnaire en df avec les clés en index"""
df= pd.DataFrame.from_dict(dico,orient=u'index',columns=[u"Poste",u"Localisation",u"Date parution",u"Référence",u"Description",u"Competences",u"Experience",u"Qualification",u"Secteur",u"Entreprise",u"Lien_Partenaire"])


print(df)
print("### Début de l'import vers la BDD")
from sqlalchemy import create_engine
import argparse
import os,configparser

parser = argparse.ArgumentParser()
parser.add_argument("-v", action="store_true", help="Verbose SQL")
parser.add_argument("--base", help="Répertoire de movies")
parser.add_argument("--bdd", help="Base de donnée")
args = parser.parse_args()

config = configparser.ConfigParser()
config.read_file(open(os.path.expanduser("~/.datalab.cnf")))

base = args.base 

#DB="PASCALICOLA?charset=utf8"
#con = create_engine("mysql://%s:%s@%s/%s" % (config['myBDD']['user'], config['myBDD']['password'], config['myBDD']['host'], DB), echo=args.v)
#df.to_sql(con=con, name='PASCALICOLAS_FINALE_ULTIME', if_exists='append')
#df.to_csv('PASCALICOLAS_FINALE.csv')
#print("### Import vers la BDD réussi")
# Affichage du temps d execution
print("Temps d execution : %s secondes ---" % (time.time() - start_time))
